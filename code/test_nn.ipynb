{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-19T15:29:16.454428Z",
     "start_time": "2024-11-19T15:29:16.451663Z"
    }
   },
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Conv2d, MaxPool2d, Flatten, L1Loss, MSELoss\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Linear\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class Wisdom(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Wisdom,self).__init__()\n",
    "        self.conv1 = Conv2d(in_channels=3, out_channels=6,kernel_size=3,stride=1,padding=0)\n",
    "        # 3 为输入通道数，6 为输出通道数,表示6个卷积核进行处理得到六个输出，3 为卷积核大小\n",
    "        self.maxpool1 = MaxPool2d(kernel_size=3,ceil_mode=False)\n",
    "        self.relu1 =ReLU() #默认 inplace=False，即不改变原数据\n",
    "        self.linear1 = Linear(196608,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=self.conv1(x)\n",
    "        return x\n",
    "    def maxpool(self,x):\n",
    "        output = self.maxpool1(x)\n",
    "        return output\n",
    "    def relu(self,x):\n",
    "        output = self.relu1(x)\n",
    "        return output\n",
    "    def linear(self,x):\n",
    "        output = self.linear1(x)\n",
    "        return output"
   ],
   "id": "413b6896392c0b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "学习module的使用，定义一个类",
   "id": "2562ca321bc6031f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#input 为输入图像\n",
    "input = torch.tensor([[1,2,0,3,1],\n",
    "                      [0,1,2,3,1],\n",
    "                      [1,2,1,0,0],\n",
    "                      [5,2,3,1,1],\n",
    "                      [2,1,0,1,1]])\n",
    "\n",
    "# kernel 为卷积核，\n",
    "kernel = torch.tensor([[1,2,1],\n",
    "                       [0,1,0],\n",
    "                       [2,1,0]])\n",
    "\n",
    "input = torch.reshape(input,(1,1,5,5))  # 1 为batch_size, 1 为通道数\n",
    "# batch_size指一次训练迭代中，模型处理的样本数量，通道数表示特征图的数量\n",
    "\n",
    "kernel = torch.reshape(kernel,(1,1,3,3))  \n",
    "\n",
    "output = F.conv2d(input, kernel, stride=1) # stride为步长,表示卷积核每次移动的距离\n",
    "print(output)\n",
    "\n",
    "output2 = F.conv2d(input, kernel, stride=2) # 卷积核每次移动的距离为2\n",
    "print(output2)\n",
    "\n",
    "output3 = F.conv2d(input, kernel, stride=1, padding=1) # padding为填充, 1表示在图像周围填充一圈0,再进行卷积操作\n",
    "print(output3)"
   ],
   "id": "9219527f97968a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "### 学习卷积操作\n",
    "$f(t)g(x-t)dt$ $f(t)$是变化函数，给定的输入，$g(x-t)$是卷积核，代表对周围参数的影响，卷积核在输入上滑动，计算卷积核与输入的乘积\n",
    "\n",
    "#### 卷积核作用：\n",
    "<ol>\n",
    "<li>对不稳定输入进行稳定输出，例如$f(x)$表示摄入食品与时间的关系，$g(x)$表示食品消化的量与时间的关系，对两个相乘函数求积分，代表胃容物总量与时间关系</li>\n",
    "<li>图像经过卷积核处理，表示周围像素点如何对当前像素产生影响，从而进行平滑处理</li>\n",
    "<li>看作对周围像素点的试探，从而得到更好的特征提取</li>\n",
    "</ol>"
   ],
   "id": "5a47452daf39724"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dataset = torchvision.datasets.CIFAR10(root='./dataset', train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=64)\n",
    "\n",
    "writer = SummaryWriter(\"logs\")\n",
    "step=0\n",
    "wisdom = Wisdom()\n",
    "for data in dataloader:\n",
    "    imgs, targets = data\n",
    "    output = wisdom(imgs)\n",
    "    print(imgs.shape)\n",
    "    print(output.shape)\n",
    "    # torch.Size([64, 3, 32, 32])\n",
    "    writer.add_images(\"input\",imgs,step)\n",
    "    # torch.Size([64, 6, 30, 30]) -> [xxx,3,30,30] 因为彩色图像有3个通道，6个通道会报错，所以需要reshape\n",
    "    # 多余部分进入batch_size\n",
    "    output = torch.reshape(output,(-1,3,30,30))\n",
    "    writer.add_images(\"output\",output,step)\n",
    "    step = step + 1\n"
   ],
   "id": "d312342c55f708f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# maxpool 用法\n",
    "input = torch.tensor([[1,2,0,3,1],\n",
    "                      [0,1,2,3,1],\n",
    "                      [1,2,1,0,0],\n",
    "                      [5,2,3,1,1],\n",
    "                      [2,1,0,1,1]])\n",
    "input = torch.reshape(input,(-1,1,5,5))\n",
    "print (input.shape)\n",
    "output = wisdom.maxpool(input)\n",
    "print(output)\n",
    "\n",
    "writer = SummaryWriter(\"logs_maxpool\")\n",
    "step=0\n",
    "for data in dataloader:\n",
    "    imgs, targets = data\n",
    "    output = wisdom.maxpool(imgs)\n",
    "    writer.add_images(\"input\",imgs,step)\n",
    "    writer.add_images(\"output\",output,step)\n",
    "    step = step + 1"
   ],
   "id": "e6d2bcd787711dc1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 最大池化操作\n",
    "池化核在输入上滑动，每次取池化核覆盖区域的最大值，得到输出\n",
    "\n",
    "默认stride=kernel_size,即池化核每次移动的距离为池化核大小\n",
    "\n",
    "若最后一次滑动不足以覆盖整个区域，则依照Ceil_model,若为true，保留最后一次滑动的最大值；若为false，舍弃最后一次滑动的最大值\n",
    "\n",
    "作用：用于减少数据维度和参数量，提高训练速度"
   ],
   "id": "53b7b385df695bd8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# relu 用法\n",
    "input = torch.tensor([[1,-0.5],\n",
    "                      [-1,3]])\n",
    "input = torch.reshape(input,(-1,1,2,2))\n",
    "wisdom = Wisdom()\n",
    "output = wisdom.relu(input)\n",
    "print(output)"
   ],
   "id": "7eb6d1ee0a8f78e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# linear 操作\n",
    "dataset = torchvision.datasets.CIFAR10(root='./dataset', train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=64)\n",
    "wisdom= Wisdom()\n",
    "for data in dataloader:\n",
    "    imgs, targets = data\n",
    "    # output = torch.reshape(imgs,(1,1,1,-1))\n",
    "    output = torch.flatten(imgs) #展平成一行\n",
    "    output = wisdom.linear1(output)\n",
    "    print (output.shape)"
   ],
   "id": "586311ba1febbde8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### linear 线性层操作\n",
    "$y = xA^T + b$，其中x为输入，A为权重，b为偏置\n",
    "\n",
    "对一个尺寸5*5的输入，先 reshape 成 1*25，只有一层然后与权重相乘，经过线性层，得到输出\n",
    "\n",
    "此处作用：将 [64,3,32,32] 的输入展平成一行  [1,1,1,196608] ，从而把特征拉平，进行线性输入\n",
    "\n",
    "然后与权重相乘，得到输出\n",
    "\n",
    "**torch.nn.Linear(in_features, out_features, bias=True)**\n",
    "\n",
    "bias为偏置，默认为True,作用是在输出上加上一个常数\n",
    "\n",
    "weight为权重，in_features为输入特征数，out_features为输出特征数"
   ],
   "id": "6320a7622f56f42a"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-11-19T15:44:25.862911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 以 cifar10 数据集为例，展示卷积神经网络的训练过程\n",
    "dataset = torchvision.datasets.CIFAR10(root='./dataset', train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=1)\n",
    "\n",
    "class Cifar10(nn.Module):  #所有步骤都按照图片中的结构进行\n",
    "    def __init__(self):\n",
    "        super(Cifar10,self).__init__()\n",
    "        # self.conv1 = Conv2d(3,32,5,padding=2)\n",
    "        # self.maxpool1 = MaxPool2d(2)\n",
    "        # self.conv2 = Conv2d(32,32,5,padding=2)\n",
    "        # self.maxpool2 = MaxPool2d(2)\n",
    "        # self.conv3= Conv2d(32,64,5,padding=2)\n",
    "        # self.maxpool3 = MaxPool2d(2)\n",
    "        # self.flatten = Flatten()\n",
    "        # self.linear1 = Linear(64*4*4,64)\n",
    "        # self.linear2 = Linear(64,10)\n",
    "\n",
    "        # 简化写法,直接用Sequential将所有层连接起来\n",
    "        self.model1 = nn.Sequential(\n",
    "            Conv2d(3,32,5,padding=2),\n",
    "            MaxPool2d(2),\n",
    "            Conv2d(32,32,5,padding=2),\n",
    "            MaxPool2d(2),\n",
    "            Conv2d(32,64,5,padding=2),\n",
    "            MaxPool2d(2),\n",
    "            Flatten(),\n",
    "            Linear(64*4*4,64),\n",
    "            Linear(64,10)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        # x = self.conv1(x)\n",
    "        # x= self.maxpool1(x)\n",
    "        # x = self.conv2(x)\n",
    "        # x = self.maxpool2(x)\n",
    "        # x = self.conv3(x)\n",
    "        # x = self.maxpool3(x)\n",
    "        # x = self.flatten(x)\n",
    "        # x = self.linear1(x)\n",
    "        # x = self.linear2(x)\n",
    "        x=self.model1(x)\n",
    "        return x\n",
    "\n",
    "wisdom = Cifar10()\n",
    "# print(wisdom)\n",
    "# input = torch.randn(64,3,32,32)\n",
    "'''\n",
    "用来检验网络结构是否正确，若是发生报错，说明网络结构有问题\n",
    "input = torch.randn(64,3,32,32)\n",
    "output = wisdom(input)\n",
    "print(output.shape)\n",
    "'''\n",
    "\n",
    "# writer = SummaryWriter(\"../logs_cifar10\")\n",
    "# writer.add_graph(wisdom,input)  #将网络结构写入tensorboard,graph用于展示网络结构，特别好用！\n",
    "# writer.close()\n",
    "loss = nn.CrossEntropyLoss()\n",
    "# CrossEntropyLoss 用于多分类问题，计算交叉熵损失\n",
    "# 公式为：$loss(x,class) = -log(\\frac{exp(x[class])}{\\sum_j exp(x[j])})$\n",
    "\n",
    "for data in dataloader:\n",
    "    imgs, targets = data\n",
    "    output = wisdom(imgs)\n",
    "    result_loss = loss(output,targets)\n",
    "    result_loss.backward()\n",
    "    print(result_loss)\n",
    "\n"
   ],
   "id": "9215c4c3d9d3453a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 以 $cifar10$ 数据集为例，展示卷积神经网络的训练过程 具体结构见文件夹内的图片\n",
    "$ H_{out} = \\frac{(H_{in} + 2 * padding[0] - dilation[0]*(kernel\\_size[0]-1) -1}{stride[0]} + 1 $\n",
    "\n",
    "根据这个公式计算具体参数，dilation为膨胀系数，默认为1，kernel_size为卷积核大小，stride为步长，padding为填充\n",
    "\n",
    "$H_{in}$为输入特征图大小，$H_{out}$为输出特征图大小,二者已知，都为32,最后得到padding=2, stride=1\n",
    "\n",
    "同理，经过计算得到后面步骤的参数\n"
   ],
   "id": "92e48e2f1548e330"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T15:29:21.788526Z",
     "start_time": "2024-11-19T15:29:21.782203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# loss function\n",
    "inputs = torch.tensor([1,2,3],dtype=torch.float32)\n",
    "targets = torch.tensor([1,2,5],dtype=torch.float32)\n",
    "\n",
    "inputs = torch.reshape(inputs,(1,1,1,3))\n",
    "targets = torch.reshape(targets,(1,1,1,3))\n",
    "\n",
    "loss = L1Loss(reduction='mean')\n",
    "result = loss(inputs,targets)\n",
    "\n",
    "loss_mse = MSELoss(reduction='mean')\n",
    "result_mse = loss_mse(inputs,targets)\n",
    "# mse 用来计算均方误差，l1 用来计算绝对值误差\n",
    "print(result)\n",
    "print(result_mse)"
   ],
   "id": "cb62e0cf3fea9fa1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6667)\n",
      "tensor(1.3333)\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### loss function\n",
    "<li> 计算实际输出和目标之间的差距 </li>\n",
    "<li> 为我们更新输出提供一定的依据（反向传播） </li>"
   ],
   "id": "5cea34eedfd3019b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
